{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4abddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Job Title        5000 non-null   object\n",
      " 1   Job Category     5000 non-null   object\n",
      " 2   Company          5000 non-null   object\n",
      " 3   Salary           5000 non-null   object\n",
      " 4   Skills Required  5000 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 195.4+ KB\n",
      "None\n",
      "                      Job Title       Job Category    Company  Salary  \\\n",
      "0  Digital Marketing Specialist  Digital Marketing       Meta  12 LPA   \n",
      "1              Business Analyst  Business Analysis    Infosys  10 LPA   \n",
      "2  Digital Marketing Specialist  Digital Marketing      Cisco   8 LPA   \n",
      "3               DevOps Engineer             DevOps  Microsoft  24 LPA   \n",
      "4              Business Analyst  Business Analysis        IBM  10 LPA   \n",
      "\n",
      "                                     Skills Required  \n",
      "0  SEM, Email Marketing, Content Marketing, Googl...  \n",
      "1  Power BI, Business Analysis, Requirement Gathe...  \n",
      "2                         SEO, SEM, Google Analytics  \n",
      "3              Linux, AWS, CI/CD, Docker, Kubernetes  \n",
      "4  Business Analysis, Power BI, SQL, Requirement ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('job_skills_dataset_corrected.csv')\n",
    "\n",
    "# Show basic info\n",
    "print(df.info())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f5bae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Clean and normalize skills\n",
    "df['Skills Required'] = df['Skills Required'].str.lower().str.replace(r'[^\\w\\s,]', '', regex=True)\n",
    "\n",
    "# Feature and target\n",
    "X_raw = df['Skills Required']\n",
    "y_raw = df['Job Title']\n",
    "\n",
    "# Vectorize skills\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(','))\n",
    "X = vectorizer.fit_transform(X_raw)\n",
    "\n",
    "# Encode job titles\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_raw)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c87828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 117), (1000, 117), 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c723160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.999,\n",
       " '                              precision    recall  f1-score   support\\n\\n                 AI Engineer       1.00      1.00      1.00        86\\n           Backend Developer       1.00      1.00      1.00        87\\n            Business Analyst       1.00      1.00      1.00        84\\n              Cloud Engineer       0.98      1.00      0.99        64\\n                Data Analyst       1.00      1.00      1.00        87\\n      Database Administrator       1.00      1.00      1.00        79\\n             DevOps Engineer       1.00      0.99      0.99        73\\nDigital Marketing Specialist       1.00      1.00      1.00        78\\n          Frontend Developer       1.00      1.00      1.00        84\\n              Java Developer       1.00      1.00      1.00        83\\n            Security Analyst       1.00      1.00      1.00       105\\n       Senior Data Scientist       1.00      1.00      1.00        90\\n\\n                    accuracy                           1.00      1000\\n                   macro avg       1.00      1.00      1.00      1000\\n                weighted avg       1.00      1.00      1.00      1000\\n',\n",
       " array([[ 86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,  87,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,  84,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,  64,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  87,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  79,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   1,   0,   0,  72,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  78,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  84,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  83,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 105,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  90]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy, report, conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da657556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AWS, Docker, Kubernetes, CI/CD, Linux': 'Cloud Engineer',\n",
       " 'SEO, Google Ads, Email Marketing, Content Writing': 'Digital Marketing Specialist',\n",
       " 'Power BI, Business Analysis, SQL, Requirement Gathering': 'Business Analyst',\n",
       " 'React, JavaScript, CSS, HTML': 'Frontend Developer',\n",
       " 'Python, Machine Learning, Deep Learning, NLP': 'AI Engineer'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a test function to predict job title from a custom skill string\n",
    "def predict_job_title(skill_string):\n",
    "    skill_string = skill_string.lower()\n",
    "    skill_vector = vectorizer.transform([skill_string])\n",
    "    prediction = lr_model.predict(skill_vector)\n",
    "    job_title = label_encoder.inverse_transform(prediction)[0]\n",
    "    return job_title\n",
    "\n",
    "# Test with a few custom skill inputs\n",
    "test_inputs = [\n",
    "    \"AWS, Docker, Kubernetes, CI/CD, Linux\",\n",
    "    \"SEO, Google Ads, Email Marketing, Content Writing\",\n",
    "    \"Power BI, Business Analysis, SQL, Requirement Gathering\",\n",
    "    \"React, JavaScript, CSS, HTML\",\n",
    "    \"Python, Machine Learning, Deep Learning, NLP\"\n",
    "]\n",
    "\n",
    "predictions = {skills: predict_job_title(skills) for skills in test_inputs}\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41148a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.999\n",
      "Random Forest Accuracy: 0.999\n",
      "SVM Accuracy: 0.999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "\n",
    "# Train SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_acc = accuracy_score(y_test, svm_model.predict(X_test))\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {accuracy}\")\n",
    "print(f\"Random Forest Accuracy: {rf_acc}\")\n",
    "print(f\"SVM Accuracy: {svm_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbb51e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Replace this cell:\n",
    "# vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(','))\n",
    "\n",
    "# With this:\n",
    "from utils import comma_tokenizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=comma_tokenizer)\n",
    "vectorizer.fit(X_raw) \n",
    "# Save vectorizer and label encoder\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "# Save all models\n",
    "joblib.dump(lr_model, 'logistic_regression_model.pkl')\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "joblib.dump(svm_model, 'svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3d4208a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Skill list generated with 66 unique entries.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both datasets\n",
    "df1 = pd.read_csv(\"job_skills_dataset_corrected.csv\")\n",
    "df2 = pd.read_csv(\"learning_resources_dataset.csv\")\n",
    "\n",
    "skill_set = set()\n",
    "\n",
    "# Extract from job_skills_dataset_corrected.csv\n",
    "for row in df1[\"Skills Required\"]:\n",
    "    for skill in str(row).split(\",\"):\n",
    "        cleaned = skill.strip().lower()\n",
    "        if cleaned:\n",
    "            skill_set.add(cleaned)\n",
    "\n",
    "# Attempt from learning_resources_dataset.csv if skill-related column exists\n",
    "for col in df2.columns:\n",
    "    if \"skill\" in col.lower():\n",
    "        for entry in df2[col]:\n",
    "            for skill in str(entry).split(\",\"):\n",
    "                cleaned = skill.strip().lower()\n",
    "                if cleaned:\n",
    "                    skill_set.add(cleaned)\n",
    "\n",
    "# Save as unique_skills.txt\n",
    "with open(\"unique_skills.txt\", \"w\") as f:\n",
    "    for skill in sorted(skill_set):\n",
    "        f.write(skill + \"\\n\")\n",
    "\n",
    "print(\"✅ Skill list generated with\", len(skill_set), \"unique entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db7051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fdfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed598c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
